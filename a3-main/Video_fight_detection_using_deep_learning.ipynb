{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doctor9Trio/a3/blob/main/Video_fight_detection_using_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fight detection in Video"
      ],
      "metadata": {
        "id": "jqS3IiGYwCXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NFT Assignment\n",
        "\n",
        "\n",
        "*   BT21CSE011 - Vishal Raj\n",
        "*   BT21CSE117 - Ravi Bishnoi\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "#### In this Assignment we have to Train the model to detect Fight in Video with help of Neural Network.\n",
        "\n",
        "#### Due to the small size of the provided dataset, the model tend to overfit quickly. For Better results we have to train this model with a large datasets.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BcA6BIHDwCXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Scikit-Video"
      ],
      "metadata": {
        "id": "oPgFl2NtwCXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-video"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:05:38.800170Z",
          "iopub.execute_input": "2022-10-11T15:05:38.801172Z",
          "iopub.status.idle": "2022-10-11T15:05:48.979367Z",
          "shell.execute_reply.started": "2022-10-11T15:05:38.801130Z",
          "shell.execute_reply": "2022-10-11T15:05:48.978083Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yqh-UpcwCXp",
        "outputId": "aa717bd2-1113-40fe-82fe-2159f7fbbec9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "y6kRCvbHwCXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import skvideo.io\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import io\n",
        "import imageio\n",
        "import ipywidgets\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-10-11T15:05:36.239243Z",
          "iopub.execute_input": "2022-10-11T15:05:36.240429Z",
          "iopub.status.idle": "2022-10-11T15:05:38.049830Z",
          "shell.execute_reply.started": "2022-10-11T15:05:36.240383Z",
          "shell.execute_reply": "2022-10-11T15:05:38.048763Z"
        },
        "trusted": true,
        "id": "fmYXND3LwCXn"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add surveillance fight dataset from github"
      ],
      "metadata": {
        "id": "0-rBM_y7wCXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Doctor9Trio/a3.git"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:05:48.982299Z",
          "iopub.execute_input": "2022-10-11T15:05:48.982716Z",
          "iopub.status.idle": "2022-10-11T15:05:49.943618Z",
          "shell.execute_reply.started": "2022-10-11T15:05:48.982673Z",
          "shell.execute_reply": "2022-10-11T15:05:49.942419Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9oHpdipwCXq",
        "outputId": "738a80ec-f538-4cbc-b4d5-882324e2e41a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'a3' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load, resize and trim the videos"
      ],
      "metadata": {
        "id": "RW0W1YJPwCXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frame_crop_center(video,cropf):\n",
        "    f,_,_,_ = video.shape\n",
        "    startf = f//2 - cropf//2\n",
        "    return video[startf:startf+cropf, :, :, :]\n",
        "\n",
        "fights=[]\n",
        "nofights=[]\n",
        "\n",
        "surv_fights=[]\n",
        "surv_no_fights=[]\n",
        "\n",
        "video_dims = []\n",
        "\n",
        "####### Fight data\n",
        "for filename in os.listdir('/content/a3/fight'):\n",
        "    f = os.path.join('/content/a3/fight', filename)\n",
        "    # checking if it is a file\n",
        "    video = skvideo.io.vread(f)\n",
        "    video_dims.append(video.shape)\n",
        "    L=[]\n",
        "\n",
        "    #resize video dimensions\n",
        "    for i in range(video.shape[0]):\n",
        "      frame = cv2.resize(video[i], (128,128), interpolation=cv2.INTER_CUBIC)\n",
        "      L.append(frame)\n",
        "\n",
        "    video = np.asarray(L)\n",
        "\n",
        "    #center crop video to have consistent video frame number\n",
        "    video = frame_crop_center(video, 42)\n",
        "\n",
        "    fights.append(video)\n",
        "\n",
        "for filename in os.listdir('/content/a3/fight'):\n",
        "    f = os.path.join('/content/a3/fight', filename)\n",
        "    # checking if it is a file\n",
        "    video = skvideo.io.vread(f)\n",
        "    video_dims.append(video.shape)\n",
        "\n",
        "    L=[]\n",
        "    for i in range(video.shape[0]):\n",
        "      frame = cv2.resize(video[i], (128,128), interpolation=cv2.INTER_CUBIC)\n",
        "      L.append(frame)\n",
        "\n",
        "    video = np.asarray(L)\n",
        "    video = frame_crop_center(video, 42)\n",
        "\n",
        "    surv_fights.append(video)\n",
        "\n",
        "####### Non Fight data\n",
        "for filename in os.listdir('/content/a3/noFight'):\n",
        "    f = os.path.join('/content/a3/noFight', filename)\n",
        "    # checking if it is a file\n",
        "    video = skvideo.io.vread(f)\n",
        "    video_dims.append(video.shape)\n",
        "\n",
        "    L=[]\n",
        "    for i in range(video.shape[0]):\n",
        "      frame = cv2.resize(video[i], (128,128), interpolation=cv2.INTER_CUBIC)\n",
        "      L.append(frame)\n",
        "\n",
        "    video = np.asarray(L)\n",
        "    video = frame_crop_center(video, 42)\n",
        "\n",
        "    nofights.append(video)\n",
        "\n",
        "for filename in os.listdir('/content/a3/noFight'):\n",
        "    f = os.path.join('/content/a3/noFight', filename)\n",
        "    # checking if it is a file\n",
        "    video = skvideo.io.vread(f)\n",
        "    video_dims.append(video.shape)\n",
        "\n",
        "    L=[]\n",
        "    for i in range(video.shape[0]):\n",
        "      frame = cv2.resize(video[i], (128,128), interpolation=cv2.INTER_CUBIC)\n",
        "      L.append(frame)\n",
        "\n",
        "    video = np.asarray(L)\n",
        "    video = frame_crop_center(video, 42)\n",
        "\n",
        "    surv_no_fights.append(video)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:05:49.945914Z",
          "iopub.execute_input": "2022-10-11T15:05:49.946338Z",
          "iopub.status.idle": "2022-10-11T15:09:26.319594Z",
          "shell.execute_reply.started": "2022-10-11T15:05:49.946294Z",
          "shell.execute_reply": "2022-10-11T15:09:26.317992Z"
        },
        "trusted": true,
        "id": "ZMXG-RT8wCXq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video duration and dimension analysis"
      ],
      "metadata": {
        "id": "bMMJ9NdbwCXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean number of frames in the videos is 54 which corresponds to around 2 seconds.\n",
        "To make the video duration consistent without losing lots of data the videos are trimmed to have 42 frames in total with a center crop.\n",
        "\n",
        "Using a smaller frame number results in poorer performance."
      ],
      "metadata": {
        "id": "o6TG9V4QwCXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.DataFrame(video_dims, columns=['frame_length', 'height', 'width', 'channels'])\n",
        "data.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:09:26.323828Z",
          "iopub.execute_input": "2022-10-11T15:09:26.325101Z",
          "iopub.status.idle": "2022-10-11T15:09:26.361603Z",
          "shell.execute_reply.started": "2022-10-11T15:09:26.325049Z",
          "shell.execute_reply": "2022-10-11T15:09:26.360583Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "y2gt9egHwCXs",
        "outputId": "193de716-f90a-45dd-b2cd-63e1f1f1a385"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       frame_length      height       width  channels\n",
              "count     16.000000   16.000000   16.000000      16.0\n",
              "mean      65.875000  345.000000  473.250000       3.0\n",
              "std       12.409002   40.987803   18.444511       0.0\n",
              "min       50.000000  240.000000  426.000000       3.0\n",
              "25%       58.250000  360.000000  480.000000       3.0\n",
              "50%       61.500000  360.000000  480.000000       3.0\n",
              "75%       78.000000  360.000000  480.000000       3.0\n",
              "max       85.000000  360.000000  480.000000       3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25878c50-8b6f-425b-abcf-d979f2e90b52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame_length</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>channels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>65.875000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>473.250000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.409002</td>\n",
              "      <td>40.987803</td>\n",
              "      <td>18.444511</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>426.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>58.250000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>61.500000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>85.000000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25878c50-8b6f-425b-abcf-d979f2e90b52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25878c50-8b6f-425b-abcf-d979f2e90b52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25878c50-8b6f-425b-abcf-d979f2e90b52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-913389e5-7ff6-4e71-a81b-b33a139bd9db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-913389e5-7ff6-4e71-a81b-b33a139bd9db')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-913389e5-7ff6-4e71-a81b-b33a139bd9db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate data and create labels"
      ],
      "metadata": {
        "id": "uWeZy5IWwCXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "surv_fights = [video for video in surv_fights if video.shape[0] == 42]\n",
        "surv_no_fights = [video for video in surv_no_fights if video.shape[0] == 42]\n",
        "\n",
        "videos = fights + surv_fights + nofights + surv_no_fights\n",
        "videos = np.asarray(videos)\n",
        "\n",
        "labels = np.concatenate([np.ones(len(fights)+len(surv_fights)) , np.zeros(len(nofights)+len(surv_no_fights))])\n",
        "\n",
        "del fights\n",
        "del nofights\n",
        "del surv_fights\n",
        "del surv_no_fights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:09:26.363434Z",
          "iopub.execute_input": "2022-10-11T15:09:26.364124Z",
          "iopub.status.idle": "2022-10-11T15:09:26.676061Z",
          "shell.execute_reply.started": "2022-10-11T15:09:26.364085Z",
          "shell.execute_reply": "2022-10-11T15:09:26.674962Z"
        },
        "trusted": true,
        "id": "ZLMuPIM8wCXs"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train, test, val split"
      ],
      "metadata": {
        "id": "XTJsRZPlwCXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(videos, labels, test_size=0.2, random_state=2334)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=124567)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:09:26.677668Z",
          "iopub.execute_input": "2022-10-11T15:09:26.678086Z",
          "iopub.status.idle": "2022-10-11T15:09:27.240610Z",
          "shell.execute_reply.started": "2022-10-11T15:09:26.678043Z",
          "shell.execute_reply": "2022-10-11T15:09:27.239376Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzHdFLBlwCXt",
        "outputId": "aeeda12f-5085-4047-a723-7a93f540255a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 42, 128, 128, 3)\n",
            "(2, 42, 128, 128, 3)\n",
            "(4, 42, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set ANN model hyperparameters"
      ],
      "metadata": {
        "id": "XFN1CXiLwCXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN Hyperparameters\n",
        "SEED = 77\n",
        "BATCH_SIZE = 4\n",
        "INPUT_SHAPE = (128, 128, 3)  # Adjusted input shape to match your data\n",
        "NUM_CLASSES = 2\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "EPOCHS = 10\n",
        "\n",
        "# You can keep these parameters for the ANN model architecture if desired\n",
        "PATCH_SIZE = (8, 8, 8)\n",
        "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
        "\n",
        "# The following parameters are specific to the ViVit model and may not apply to a basic ANN\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 64\n",
        "NUM_HEADS = 2\n",
        "NUM_LAYERS = 2\n"
      ],
      "metadata": {
        "id": "04D8VSHSyQVV"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed for reproducibility\n",
        "SEED = 77\n",
        "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# DATA\n",
        "DATASET_NAME = \"fight/nofights\"\n",
        "BATCH_SIZE = 4\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "INPUT_SHAPE = (42, 128, 128, 3)\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "# TRAINING\n",
        "EPOCHS = 10\n",
        "\n",
        "# TUBELET EMBEDDING\n",
        "PATCH_SIZE = (8, 8, 8)\n",
        "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
        "\n",
        "# ViViT ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 64\n",
        "NUM_HEADS = 2\n",
        "NUM_LAYERS = 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:09:27.242417Z",
          "iopub.execute_input": "2022-10-11T15:09:27.243408Z",
          "iopub.status.idle": "2022-10-11T15:09:27.252868Z",
          "shell.execute_reply.started": "2022-10-11T15:09:27.243361Z",
          "shell.execute_reply": "2022-10-11T15:09:27.251656Z"
        },
        "trusted": true,
        "id": "ZEa7Ut8cwCXt"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess and prepare dataloader"
      ],
      "metadata": {
        "id": "VfYHF8MgwCXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes around 10 to 20 seconds to execute"
      ],
      "metadata": {
        "id": "qyAPGP8owCXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
        "    \"\"\"Preprocess the frames tensors and parse the labels\"\"\"\n",
        "    # Preprocess images\n",
        "    frames = tf.image.convert_image_dtype(\n",
        "        frames[\n",
        "            ..., tf.newaxis\n",
        "        ],  # The new axis is to help for further processing with Conv3D layers\n",
        "        tf.float32,\n",
        "    )\n",
        "\n",
        "    # Parse label\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    return frames, label\n",
        "\n",
        "\n",
        "def prepare_dataloader(\n",
        "    videos: np.ndarray,\n",
        "    labels: np.ndarray,\n",
        "    loader_type: str = \"train\",\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "):\n",
        "    \"\"\"Utility function to prepare dataloader\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
        "\n",
        "    if loader_type == \"train\":\n",
        "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
        "\n",
        "    dataloader = (\n",
        "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "trainloader = prepare_dataloader(X_train, y_train, \"train\")\n",
        "validloader = prepare_dataloader(X_val, y_val, \"valid\")\n",
        "testloader = prepare_dataloader(X_test, y_test, \"test\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "hQt35IdEwCXu"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define some model classes"
      ],
      "metadata": {
        "id": "eotQbyLpwCXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TubeletEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection = layers.Conv3D(\n",
        "            filters=embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            strides=patch_size,\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
        "\n",
        "    def call(self, videos):\n",
        "        projected_patches = self.projection(videos)\n",
        "        flattened_patches = self.flatten(projected_patches)\n",
        "        return flattened_patches\n",
        "\n",
        "class PositionalEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, num_tokens, _ = input_shape\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_tokens, output_dim=self.embed_dim\n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
        "\n",
        "    def call(self, encoded_tokens):\n",
        "        # Encode the positions and add it to the encoded tokens\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_tokens = encoded_tokens + encoded_positions\n",
        "        return encoded_tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:09:31.483636Z",
          "iopub.execute_input": "2022-10-11T15:09:31.484014Z",
          "iopub.status.idle": "2022-10-11T15:09:31.493400Z",
          "shell.execute_reply.started": "2022-10-11T15:09:31.483976Z",
          "shell.execute_reply": "2022-10-11T15:09:31.492281Z"
        },
        "trusted": true,
        "id": "4AEE6Y_AwCXu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "WUmX1POFwCXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_ann_model(input_shape, num_classes):\n",
        "    model = keras.Sequential([\n",
        "        # Flatten the input\n",
        "        layers.Flatten(input_shape=input_shape),\n",
        "        # Add a dense layer with ReLU activation\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        # Add a dropout layer for regularization\n",
        "        layers.Dropout(0.5),\n",
        "        # Add the output layer with softmax activation for classification\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Example usage of the ANN model creation function\n",
        "input_shape = (128, 128, 3)  # Replace with your desired input shape\n",
        "num_classes = 2  # Replace with the number of classes\n",
        "ann_model = create_ann_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model with an appropriate optimizer and loss function\n",
        "ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "ann_model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:09:31.498013Z",
          "iopub.execute_input": "2022-10-11T15:09:31.498676Z",
          "iopub.status.idle": "2022-10-11T15:09:31.511114Z",
          "shell.execute_reply.started": "2022-10-11T15:09:31.498636Z",
          "shell.execute_reply": "2022-10-11T15:09:31.509927Z"
        },
        "trusted": true,
        "id": "5Taaxqh-wCXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4ff542-a8e7-47db-fecc-086da8fe3c60"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 49152)             0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               6291584   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6291842 (24.00 MB)\n",
            "Trainable params: 6291842 (24.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define metrics, build, train and save ANN Model"
      ],
      "metadata": {
        "id": "fuMJN-rIwCXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Define custom metrics\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "# Define constants for the ANN\n",
        "INPUT_SHAPE = (128, 128, 3)  # Replace with the desired input shape\n",
        "NUM_CLASSES = 2  # Replace with the number of classes\n",
        "LEARNING_RATE = 1e-4  # Replace with the desired learning rate\n",
        "EPOCHS = 10  # Replace with the desired number of epochs\n",
        "\n",
        "# Define mock data (replace with your actual data loading logic)\n",
        "num_samples = 1000\n",
        "x_train = np.random.rand(num_samples, *INPUT_SHAPE)\n",
        "y_train = np.random.randint(NUM_CLASSES, size=num_samples)\n",
        "x_valid = np.random.rand(num_samples // 5, *INPUT_SHAPE)\n",
        "y_valid = np.random.randint(NUM_CLASSES, size=num_samples // 5)\n",
        "\n",
        "# Define the ANN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=INPUT_SHAPE),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with the optimizer, loss function, and metrics\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\n",
        "        tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "        recall_m,\n",
        "        precision_m,\n",
        "        f1_m,\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the ANN model\n",
        "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=(x_valid, y_valid))\n",
        "\n",
        "# Evaluate the model on the test data (replace with your test data)\n",
        "# test_loss, test_accuracy, test_recall, test_precision, test_f1 = model.evaluate(testloader)\n",
        "# print(f\"Test accuracy: {round(test_accuracy * 100, 2)}%\")\n",
        "# print(f\"Test recall: {round(test_recall * 100, 2)}%\")\n",
        "# print(f\"Test precision: {round(test_precision * 100, 2)}%\")\n",
        "# print(f\"Test F1: {round(test_f1 * 100, 2)}%\")\n",
        "\n",
        "# Save the trained ANN model\n",
        "model.save('/content/a3/ann_model.h5')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-11T15:09:31.512684Z",
          "iopub.execute_input": "2022-10-11T15:09:31.513097Z",
          "iopub.status.idle": "2022-10-11T15:11:11.017289Z",
          "shell.execute_reply.started": "2022-10-11T15:09:31.513061Z",
          "shell.execute_reply": "2022-10-11T15:11:11.016180Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYXqIjQCwCXw",
        "outputId": "fdd4aab0-c0a6-4da3-8486-7208f64d55cb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 49152)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               6291584   \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6291842 (24.00 MB)\n",
            "Trainable params: 6291842 (24.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 3s 66ms/step - loss: 1.0941 - accuracy: 0.5030 - recall_m: 1.0000 - precision_m: 0.5234 - f1_m: 0.6847 - val_loss: 0.6973 - val_accuracy: 0.4550 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.6875 - accuracy: 0.5210 - recall_m: 1.0000 - precision_m: 0.5264 - f1_m: 0.6844 - val_loss: 0.7017 - val_accuracy: 0.5400 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 73ms/step - loss: 0.6914 - accuracy: 0.5190 - recall_m: 1.0000 - precision_m: 0.5264 - f1_m: 0.6828 - val_loss: 0.6947 - val_accuracy: 0.4600 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.6927 - accuracy: 0.5220 - recall_m: 1.0000 - precision_m: 0.5205 - f1_m: 0.6802 - val_loss: 0.6935 - val_accuracy: 0.4600 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.6946 - accuracy: 0.5280 - recall_m: 1.0000 - precision_m: 0.5264 - f1_m: 0.6851 - val_loss: 0.6930 - val_accuracy: 0.5400 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.6930 - accuracy: 0.5240 - recall_m: 1.0000 - precision_m: 0.5322 - f1_m: 0.6888 - val_loss: 0.6929 - val_accuracy: 0.5400 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.6930 - accuracy: 0.5240 - recall_m: 1.0000 - precision_m: 0.5264 - f1_m: 0.6851 - val_loss: 0.6929 - val_accuracy: 0.5400 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.6930 - accuracy: 0.5240 - recall_m: 1.0000 - precision_m: 0.5205 - f1_m: 0.6777 - val_loss: 0.6928 - val_accuracy: 0.5400 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 3s 110ms/step - loss: 0.6929 - accuracy: 0.5240 - recall_m: 1.0000 - precision_m: 0.5293 - f1_m: 0.6861 - val_loss: 0.6928 - val_accuracy: 0.5400 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.6929 - accuracy: 0.5240 - recall_m: 1.0000 - precision_m: 0.5264 - f1_m: 0.6872 - val_loss: 0.6927 - val_accuracy: 0.5400 - val_recall_m: 1.0000 - val_precision_m: 0.5357 - val_f1_m: 0.6967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import keras.backend as K\n",
        "\n",
        "# Define custom metric functions\n",
        "def recall_m(y_true, y_pred):\n",
        "    # Your recall metric code here\n",
        "    pass\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    # Your precision metric code here\n",
        "    pass\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    # Your F1 metric code here\n",
        "    pass\n",
        "\n",
        "# Register the custom metric functions\n",
        "custom_objects = {'recall_m': recall_m, 'precision_m': precision_m, 'f1_m': f1_m}\n",
        "\n",
        "# Load the model with custom metrics\n",
        "model = load_model('/content/a3/ann_model.h5', custom_objects=custom_objects)\n"
      ],
      "metadata": {
        "id": "CcvY6Yic6x2a"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working\n"
      ],
      "metadata": {
        "id": "stf2KM7K7yRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained fight detection model with custom metrics\n",
        "model = tf.keras.models.load_model(\n",
        "    '/content/a3/ann_model.h5',\n",
        "    custom_objects={'recall_m': recall_m, 'precision_m': precision_m, 'f1_m': f1_m}\n",
        ")\n",
        "\n",
        "# Open the video file\n",
        "video_path = '/content/a3/test.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "\n",
        "# Check if the video file was successfully opened\n",
        "if not cap.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "    # Read the frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        print(\"Error reading video frame\")\n",
        "        break\n",
        "\n",
        "    # Preprocess the frame\n",
        "    frame = cv2.resize(frame, (128, 128))  # Resize the frame to (128, 128)\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB color format\n",
        "    frame = frame / 255.0  # Normalize pixel values to the range [0, 1]\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    prediction = model.predict(np.expand_dims(frame, axis=0))\n",
        "\n",
        "    # Assuming 0.5 as a threshold for fight detection\n",
        "    is_fight = prediction[0][0] > 0.5\n",
        "\n",
        "    if is_fight:\n",
        "        # Take action when a fight is detected\n",
        "        print(\"Fight detected!\")\n",
        "\n",
        "    # Display the frame with detection result\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Introduce a delay for frame display (e.g., 10 milliseconds)\n",
        "    cv2.waitKey(10)\n",
        "\n",
        "    # Exit the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video file and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFWybQVJBVzk",
        "outputId": "bb447325-fa5c-4cd6-c010-00eb7042a98e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error opening video file\n",
            "Error reading video frame\n"
          ]
        }
      ]
    }
  ]
}